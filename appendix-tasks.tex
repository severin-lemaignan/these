\chapter{Task representation in the ontology}
\label{appendix|tasks}

This appendix is a specific study of the representation issues that arise when
one tries to model actions, pre-conditions and post-conditions in ontologies.

\section{The challenge of task representation}

It has already been presented at chapter~\ref{chapt|krs}, managing tasks in a
robot includes these kind of cognitive capacities:


\begin{enumerate}

    \item  the ability to infer which tasks could be started at any time,

    \item  the ability to check that if we do some task, it won't bring the
    world in an inconsistent state,

    \item  more generally, the ability to predict the state of the world after
    some task execution,

    \item  retrieve tasks that should be started to achieve some result,

    \item  knowing how long a task lasts.

\end{enumerate}

These capabilities are traditionally deferred to dedicated reasoning systems
(planners) that take into account different constraints (time, current
activity, agent's desires\ldots{}) to select tasks and build plans.

The ontology, as built by the robot during its lifetime, is a model of the
world that can help the planner. It can efficiently represent some of the
knowledge required for planning and task execution:


\begin{itemize}

\item  Agents state (like, busy, reading, standing, talking\ldots{}), desires
(short or long term goals)

\item  Agents capacities (technically doable actions)

\item  Physical world state (location of objects,\ldots{})

\item  Common-sense knowledge (role, usage of objects\ldots{})

\end{itemize}

Note that this knowledge is mostly declarative. Storing of procedural knowledge
is more difficult. But we'll come to it later.

Now, what are \emph{tasks} from the ontology point of view?

\begin{enumerate}

    \item  Tasks are {\bf instances} of {\bf actions} that have some purpose.
    As it, they are instances of {\tt cyc:PurposefulAction}

    \item  The type of action can be further refined by using sub-classes of
    PurposefulAction (like {\tt cyc:Movement-TranslationEvent}, {\tt
    cyc:Reading}\ldots{} the robot is expected to provide - likely at startup -
    the list of actions it can achieve depending on its hardware)

    \item  a {\tt cyc:PurposefulAction} is {\tt cyc:performedBy} one (or
    several) {\tt cyc:EmbodiedAgent}.

\end{enumerate}


A task may have a specific context as prerequisites and reversely, may
imply some new state of the world as post-condition.  Since these two aspects
are largely symmetric, I will only discuss post-conditions.

Post-conditions are difficult to represent, because the new state of the world
they represent may contradict with the current state, thus leading to
inconsistencies. It is a fundamentally non-monotonic process.

Imagine the task: \emph{"cracking an egg"}. To build a
model of this task, we need somehow to encode the post condition: {\tt the egg
shell is broken} [stmt1].

We can as well assume that the state of the egg shell before we crack it is:
{\tt the egg shell is not broken} [stmt2].

If we add both these statements {\tt [stmt1]} and {\tt [stmt2]} in the ontology
(\ie, we assert them), the ontology becomes inconsistent, and no reasoning is
possible.

For people doing planning, there's no real issue there: that's precisely the
planner role to {\bf replace} {\tt [stmt2]} by {\tt [stmt1]} when the task is
achieved. In this case, the two statements wouldn't \emph{hold} (\ie, be
asserted to be true) at the same time, and everything remains consistent.

{\sc OpenCyc} has another powerful way to deal with \emph{possible worlds}:
{\em micro-theories}. Within a microtheory, a certain set of facts must hold.
But not necessary outside. To put it in another way, {\sc OpenCyc} doesn't
generally requires the set of facts to be consistent. Only facts asserted in a
specific microtheory must be consistent with each others.

In the egg example, it means that statements 1 and 2 can be asserted at the
same time. Two microtheories must be created as well (called {\tt
cyc:TaskState} in this case), one that would describe the world {\bf before}
the task \emph{"cracking an egg"} (it would be linked to the task by the {\tt
cyc:taskPrerequisites} predicate), one that would describe the world {\bf
after} the task completion (linked with {\tt cyc:taskToAchieve} predicate).


However the microtheories approach does not belong to the Description Logics
(it is not anymore a first order logic system), and thus considerably reduce
the practical inference capabilities.

Second problem (that is partially a consequence of the first one): none of the
standard semantic tools and languages like OWL, Protege, OWL-API, Jena or
Pellet, has a notion of microtheory.


\section{A simple case: the {\tt Move} task}

So in practice, some mitigation must be done.

Since the semantics behind {\tt cyc:TaskState}, {\tt cyc:RealizedTaskState} (an
effective, realised state of the world), {\tt cyc:taskPrerequisites}, {\tt
cyc:taskToAchieve} and {\tt cyc:taskConstraints} (that expresses specific
constraints applied during task execution) are still relevant to us, the
question is: how to build a {\tt cyc:TaskState} without {\tt cyc:Microtheory}?

A simple yet ``real world'' example, extracted from the
LAAS' HATP planner task model, helps to illustrate the problem:

\begin{alltt}

action Move(Agent ag1, Place p1, Place p2)
 {
   preconditions
   {
     p1 != p2;
     ag1.posTopo == p1;
   };

   effects
   { ag1.posTopo == p2; };
 } 

\end{alltt}

Pre- and post-conditions and the relations between entities ({\tt ag1}, {\tt
p1}, {\tt p2}) are easy to understand from this model.

To represent it in the ontology, we can start with the pre-condition {\tt P1 != P2}. We want to create a new kind
of {\tt cyc:TaskState} that says: "Two locations are different".

\begin{alltt}

DifferentLocationState subClassOf cyc:TaskState
forLocation hasDomain DifferentLocationState
forLocation hasRange cyc:SpatialThing-Localized

precondition1 rdf:type DifferentLocationState
precondition1 forLocation p1
precondition1 forLocation p2

\end{alltt}

\concept{precondition1} is an instance of the state
\concept{DifferentLocationState}.

Same thing for an \concept{IdenticalLocationState} and the two instances
\concept{precondition2} and \concept{postcondition1}:



\begin{alltt}

IdenticalLocationState subClassOf cyc:TaskState
forLocation hasDomain IdenticalLocationState

precondition2 rdf:type IdenticalLocationState
precondition2 forLocation ag1
precondition2 forLocation p1

postcondition1 rdf:type IdenticalLocationState
postcondition1 forLocation ag1
postcondition1 forLocation p2

\end{alltt}

We can then instantiate the task itself:

\begin{alltt}

move1 type Move
move1 performedBy ag1
move1 fromLocation p1
move1 toLocation p2
move1 taskPrerequisites precondition1
move1 taskPrerequisites precondition2
move1 taskToAchieve postcondition1

\end{alltt}

While this model is valid, we observe two issues:


\begin{itemize}

    \item  \concept{DifferentLocationState}/\concept{IdenticalLocationState}
    conditions, as formalised above, lack expressiveness: we, as robot designers,
    \emph{decide} that \emph{DifferentLocationState} means that the locations
    must be disjoint, but this rule is not explicit at the symbolic level. The
    only explicit constraint is that \concept{DifferentLocationState} or
    \concept{IdenticalLocationState} involve locations (instances of
    \concept{cyc:SpatialThing-Localized}). But we don't formally say that these
    locations must be disjoint or identical.

    \item  The abstract model of the task does not maintain the semantic: it
    merely says that a \concept{Move} task must have two preconditions, one of
    kind \emph{different location}, one of kind \emph{identical location} and
    one post-condition of type \emph{identical location}. But the fact that
    explicitly the location {\tt p1} and {\tt p2} must be different (and not,
    for instance, {\tt ag1} and {\tt p1} or even {\tt the moon} and {\tt the
    sun}) is not kept.  We set this semantic at instantiation time, but it
    seriously reduces the relevance of such a task description for anything
    useful.

\end{itemize}

As it, it's difficult to me to see the relevance of such a task model for
robotics. The original task model from HATP is ways simpler and easier to read.
But let dig a bit futher.


\section{Fluent-based approach}

An alternative approach (used at the Technical University of Munich, for
instance) is based on fluents and events.

The idea is to represent the various states of the world with instances of
\concept{Holds} and \concept{Occurs} classes, associated to a fluent and a time
(or time interval).

%Some of the fluents they use:
%
%\begin{itemize}
%\item  contains(obj, container)
%\item  supports(obj, support)
%\item  attached(obj1, obj2)
%\item  \ldots{}
%\end{itemize}

With the egg example, {\tt occurs(breaking(egg), 10.2)} (which means that the egg was broken at time
10.2s) would be represented in the ontology as:

\begin{alltt}

event231 rdf:type cyc:BreakingEvent
event231 hasObject egg

state746 rdf:type Occurs
state746 fluent event231
state746 occursAt 10.2

\end{alltt}

which relies on the reification of events.

%For situations, {\tt holds(broken(egg), [10.3, +INF])} (which formally
%mean: from time 10.3 until +INF, the statement "the egg is broken" holds) would
%become:

%\begin{alltt}
%
%fluent471 rdf:type tum:BrokenFluent
%fluent471 hasSubject egg
%
%state746 rdf:type tum:Holds
%state746 fluent fluent471
%state746 startsAt 10.3
%state746 finishsAt +INF
%
%\end{alltt}

This representation matches situation calculus (or variants like event/fluent
calculus) theories and takes explicitly into account the time (either time
points or time intervals) and is especially suited for plan representation.

However, causal relations are not addressed in this approach, which limit its
practical use to represent tasks in the ontology.

Another issue is the lack of integration with classical first-order logic
reasoners: fluents are a kind of statement reification and prevent standard
reasoners to make inference on the new state of the world after the conclusion
of some action. To put it another way: when a fluent holds, we can not directly
infer the consequences of this fluent. Even if the fluent {\tt BrokenEgg}
holds, the statement {\tt egg rdf:type cyc:Fractured} is not asserted anyhow,
and we couldn't directly query the ontology for the list of broken objects for
instance.

\section{Rules based representations}

The expressiveness issue we had with tasks represented as pure OWL statement
can be partially addressed with rules. The example below, written in SWRL, is
rewrites the \concept{IdenticalLocationState} condition
(\concept{DifferentLocationState} is similar):

\begin{alltt}

IdenticalLocationState(?state) \(\land\)
forLocation(?state, ?p1) \(\land\)
forLocation(?state, ?p2) \(\land\)
sameAs(?p1, ?p2)
\(\Rightarrow\) RealizedTaskState(?state)

\end{alltt}

%Same thing for {\tt DifferentLocationState}:

%\begin{alltt}

%DifferentLocationState(?state) \(\land\)
%forLocation(?state, ?p1) \(\land\)
%forLocation(?state, ?p2) \(\land\)
%differentFrom(?p1, ?p2)
%\(\Rightarrow\) RealizedTaskState(?state)
%
%\end{alltt}

We can now create a new class, \concept{EligibleAction}, that holds all the actions
whose pre-conditions are satisfied.

\begin{alltt}

//Define our variables
EmbodiedAgent(?ag1) \(\land\)
SpatialThing-Localized(?p1) \(\land\)
SpatialThing-Localized(?p2) \(\land\)

//Bind the Move action
Move(?action) \(\land\)
performedBy(?action, ?ag1) \(\land\)
fromLocation(?action, ?p1) \(\land\)
toLocation(?action, ?p2) \(\land\)

//Bind the agent position
hasLocation(?ag1, ?p3) \(\land\)

//Check precondition 1
DifferentLocationState(?precondition1) \(\land\)
forLocation(?precondition1, ?p1) \(\land\)
forLocation(?precondition1, ?p2) \(\land\)
RealizedTaskState(?precondition1) \(\land\)

//Check precondition 2
IdenticalLocationState(?precondition2) \(\land\)
forLocation(?precondition2, ?p1) \(\land\)
forLocation(?precondition2, ?p3) \(\land\)
RealizedTaskState(?precondition2)

\(\Rightarrow\) EligibleAction(?action)

\end{alltt}

This rule would be triggered by the reasoner if and only if:

\begin{enumerate}

    \item  At least one agent is asserted or inferred (it is bound to {\tt
    ?ag1}),

    \item  Two other, different locations have been asserted of inferred ({\tt
    ?p1} and {\tt ?p2})\footnote{Since OWL and SWRL use the Open World
    Assumption, it means that {\tt ?p1} and {\tt ?p2} must be {\bf explicitly}
    disjoint}

    \item  At least on instance of the action {\tt Move} exists ({\tt
    ?action}), performed by {\tt ?ag1} from {\tt ?p1} to {\tt ?p2}.

    \item  {\tt ?p3} will be successively bound to every current location of
    {\tt ?ag1}

    \item  One instance of a {\tt DifferentLocationState} state exists with
    {\tt ?p1} and {\tt ?p2} as locations. This state is a \emph{realised
    state} (\ie, it holds).

    \item  Symmetrically, one instance of a {\tt IdenticalLocationState}
    state exists with {\tt ?p1} and {\tt ?p3} as locations. This state is
    \emph{realised} as well.

\end{enumerate}

If all these conditions hold, then the {\tt ?action} is inferred by the
reasoner as an {\tt EligibleAction}.

Three important remarks, however:


\begin{itemize}

    \item  One could suggest to \emph{factor} the code with a rule that would say:
    "For any \concept{Action}, if all pre-conditions are \concept{RealizedState}, then the action is
    undertakeable". Somethink like:

    \begin{alltt}

    Move(?action) \(\land\)
    taskPrerequisites(?action, ?state) \(\land\)
    RealizedState(?state)
    \(\Rightarrow\) EligibleAction(?action)

    \end{alltt}

    This is not possible in OWL because of the Open World Assumption (OWA):
    there is not way to be certain that {\bf all} states are realised because there
    is no way to know {\bf all} the prerequisite states.

    \item  For post-conditions, it's important to understand that we {\bf can not}
    \emph{apply} the result of a rule to the ontology (non-monotonicity).

    It means that something like that:

    \begin{alltt}

    Move(?action) \(\land\)
    SuccessfullyCompleteAction(?action) \(\land\)
    IdenticalLocationState(?postcondition1) \(\land\)
    forLocation(?postcondition1, ?p2) \(\land\)
    forLocation(?postcondition1, ?p3) \(\land\)
    \(\Rightarrow\) RealizedState(?postcondition1)

    \end{alltt}

    or even simpler:

    \begin{alltt}

    Move(?action) \(\land\)
    SuccessfullyCompleteAction(?action) \(\land\)
    fromLocation(?action, ?p1) \(\land\)
    toLocation(?action, ?p2)
    \(\Rightarrow\) sameAs(?p1, ?p2)

    \end{alltt}

    works as expected, but only as long as the action is considered a {\tt
    SuccessfullyCompleteAction}. It means as well that if we do another movement
    ({\tt move2}) but {\tt move1} is still a {\tt SuccessfullyCompleteAction}, then
    we are likely to have an inconsistency (or unwanted inferences): the robot will
    be at several places at the same time.

    And even if we can \emph{add} somehow new statements, we can not
    \emph{retract} statement at all: it's not possible for instance to complete
    the post-condition rule to say that the agent is not anymore in {\tt p1}.

    \item  Finally, one could conversely want to use post-condition with rules to
    know if an action was successful:


    \begin{alltt}

    Move(?action) \(\land\)
    performedBy(?action, ?ag1) \(\land\)
    hasLocation(?ag1, ?p1) \(\land\)
    toLocation(?action, ?p2) \(\land\)
    sameAs(?p1, ?p2)
    \(\Rightarrow\) SuccessfullyCompleteAction(?action)

    \end{alltt}

    This does not prove that the action was successful - or did even occurred at
    all. It only says that the world is in a state that match the post-conditions
    of the action \concept{Move}.

\end{itemize}

At the end, what should we think of rule-based representations of pre- and
post-conditions? We will conclude this study on this question, but for now, it
is important to underline the complexity of writing correct SWRL rules in the
Description Logics safe space. It can however prove useful to check that the
current world state is a context that permit some actions to occur or
conversely that matches the expected outcome of some other actions.


\section{Towards a conclusion}

Our initial questions where:

\begin{enumerate}

    \item  How to express \emph{pre- and post-conditions} in the ontology? how
    the knowledge processing framework could be used to check or enforce them?

    \item  What \emph{abstract model} of a task could be formalized in the
    ontology?

    \item  How could we rely on the ontology to \emph{instantiate} tasks?

\end{enumerate}

Can our knowledge representation system help with dealing with pre- and
post-condition? Or, are ontologies and associated reasoning tool relevant for
the \emph{legality task} (are tasks performable?) and the \emph{temporal
projection task} (what will be the state of the world after some tasks are
performed?), as described by Levesque?

We have seen that standard OWL semantics does not allow for a satisfying way to
represent the complex semantic and logic of pre- and post-conditions, even in
simple case like the \concept{Move} action.

However, the rule-based approach allows us to effectively represent the full
expressiveness of these constraints, at the cost of a complex syntax and lack
of generality. Since rule language like SWRL are actually implemented in
current reasoners like Pellet, such description of task conditions could be
actually suitable for checking both that:

\begin{itemize}

    \item  the robot believes the current world state allows a given action to
    take place,

    \item  the robot believes that it reached a state where the intended
    results of an actions are realised (which may mean that either the action
    was successfully complete or that some environment changes lead to an
    equivalent state of the world)

\end{itemize}

{\it Per se} this knowledge is useful for the execution control. But it can not
replace the need for the planner to reason itself on pre- and post-conditions
since the reasoning that the ontology framework provides applies only to the
{\bf current} state of the world. Indeed, traditional first-order logic
reasoners do not offer convenient ways to build hypothetical world models
that would come as the result of some actions (in part because of the monotonic reasoning
paradigm).

Moreover, as we already stated, using such rules for post-condition only allows
to check if the post-conditions are met. It doesn't prove that the action was
achieved. More importantly, none of the various solutions we presented
above allow to \emph{apply} post-conditions to the ontology. An external module
(likely the execution control) must take care of updating the ontology according to
the consequences of the action, adding new statements and removing deprecated
facts.

It appears that representing certain \emph{states of the world} as a set of
constraints expressed as rules can be relevant. It would allow the robot to be
\emph{conscious} that a specific situation occurs. But, to be useful, these
\concept{cyc:TaskState} (which can be viewed indeed as \emph{contexts}) must be
easy to create "on the fly" by the planner or by the execution controller,
either to describe a context required by a new task or on the contrary to
express an expected situation. It could be useful to develop to this end a
library dedicated to SWRL content generation.

Last aspect: are abstract models of tasks easily and effectively representable
in our current, OWL-based, knowledge frameworks?

Brandon Ibach, one of the Pellet developers, summarises the model of the \concept{Move}
task this way (for the precondition part):

\begin{alltt}

Place
Agent [ hasPosition(Place) ]
Action
    UndertakableAction \(\leftarrow\) EligibleMove \(\land\) NonEmptyMove
    Move [ hasAgent(Agent) hasFrom(Place) hasTo(Place) ]
        EligibleMove \(\leftarrow\) Move(m) \(\land\) hasAgent(m, a) \(\land\) hasPosition(a, p) \(\land\) hasFrom(m, f) \(\land\)
sameAs(p, f)
        NonEmptyMove \(\leftarrow\) Move(m) \(\land\) hasFrom(m, f) \(\land\) hasTo(m, t) \(\land\) differentFrom(f, t)

\end{alltt}

This can be probably considered as an abstract model of the task. This model
mixes pure OWL statements with SWRL extensions. It's formally sound, but we
doubt of the practical usability of such a model for the planner.

