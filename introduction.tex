\chapter{Introduction: Human-Robot interaction and Knowledge}
\label{chapter|introduction}


This shift requires ``awareness'' of humans.

To make informed decision, the robot needs knowledge about the \emph{tasks},
the \emph{environment}, the \emph{situational context}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

List of recent successful \& highly visible robot experiments in human environment:
\begin{itemize}
    \item Amener une bierre avec le PR2 (WG)
    \item Sandwiches/popcorn at TUM
    \item expe avec Nao
\end{itemize}

Service robotics is leaving the realm of Sci-Fi, dreams and fanstasms to become
a reality. \fxwarning{find references of predictions "when robots are in our
homes}. 

Robotics is moving from technological demos to real world coworkers/companions.


Decision making on the robot can not anymore rely on a single or a few
modalities of interaction.

The perceptual layer has moved up from traditional sensing modalities (camera
images, laser scans) to synthetic sensing devices like the Kinect-based human
tracker, face recognition or SLAM-based localization.

Perceiving and understanding the environment is now mainly a matter of
rebuilding an internal, amodal, model of the environment with to interleaved
facets: a continuous, geometric world and a discrete, symbolic world.

Because we are now interested in having the robot to not live anymore in
isolation, but on contrary, in interaction with other intelligent agents, we
want to endow our systems with \emph{agency} and \emph{social skills}. This
implies that the robot is able not only to represent inanimate objects but also
other intelligences, other minds. And not only represent them, but also
interact with them, which require communication skills, ability to take
perspectives and a theory of mind.

Note that our robot comes to life in a connected world. It has to interact with
other agents that may physically exist or may be equally well disembodied.

Figure~\ref{fig|congitive-robots} proposes an organization of research fields
and projects in robotics along two dimensions, the level of social skills, and
the level of agency (the ability to \emph{act in the world}).

\begin{figure}
    \centering
    \includegraphics[width=0.7\columnwidth]{intro/social_skills.pdf}
    \caption{Towards the cognitive robot}
    \label{fig|cognitive-robots}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{A Prototypical Scenario}
\label{sect|scenario}

\begin{figure*}
	\centering
	\includegraphics[width=0.9\textwidth]{intro/brownie_scenario.jpg}
	\caption{A representation of the scenario, in the MORSE simulator}
	\label{fig|scenario}
\end{figure*}

In order to illustrate what we consider to be the required features of a
knowledge representation system for robotics, we introduce in this section an
(imaginary) demonstration scenario.

While devising a scenario inevitably constraints the breadth of abilities we
examine, we insist on the fact that our main purpose here is to ground into a
concrete case the set of representational features we consider as desirable.

We entitle our scenario ``the Brownie scenario'' (Figure~\ref{fig|scenario}):
Robi and Roba are two service robots, that can freely
move and pick objects around (with possibly different hardware and softwares
architectures, including different knowledge representation systems). They
cooperate with a human in a kitchen environment.

The main task of the scenario is the joint realization of a brownie, initiated
by the human: ``Let's make a brownie for tonight!''.

The scenario is successful if the task is achieved (the brownie is baked) in a
reasonable time (typically shorter than what it would have been required by the
human alone).

We voluntarily do not detail the subtasks of the scenario, neither we define
how they are shared amongst agents. In our analysis we focus on the general,
\textit{a priori} representational needs of the scenario.

A ``first-order'' analysis of this task leads to a rough partition of the
required representation abilities:

\begin{enumerate}

	\item Representation abilities related to the execution of a complex
	spatio-temporal task,

	\item Representation abilities related to cooperation with other agents.

\end{enumerate}

% Representation of a complex task
We can further refine these categories: to prepare and bake a brownie, the
robot first needs to make sense of the term \emph{brownie} itself: what is it?
what is it used for? what is it made of? etc. We call this knowledge
\emph{common-sense knowledge} and the robot must be able not only to represent
it, but also to have access to an initial source (for instance through a initial
set of facts that are made available at startup, or via access to a Web-based
knowledge base like Wikipedia, etc.)

Once bound to the action \emph{make}, this should lead the robot to build and
represent a \emph{context}: we are in a scenario involving cooking. The context
enables the robot to retrieve more common-sense knowledge, like that actions
related to cooking often take place in the kitchen, cooking requires
ingredients, utensils and a procedure that may be provided by a recipe.

These last assertions imply several other features for our knowledge
representation system: ``cooking often takes place in the kitchen'' implies
that representation of both uncertainty and likelihood is desirable. The fact
that cooking is associated to a place further implies that the system models
locations and is able to attach \emph{thematic relations} to concept
(here, the likely location of the cooking action).

``cooking requires ingredients'' hints about another very common feature
available in most knowledge representation systems: \emph{reasoning}. The robot
can \emph{infers} that cooking may require a recipe since a list of ingredients
is a pre-requisite of the cooking action, and a recipe may provide such a list.
If we omit the ``may'', this is a typical example of first-order logic
reasoning. Many other reasoning techniques exist (including probabilistic ones
-- ones able to deal with the ``may''), we shall illustrate some of them later
in this scenario.

We mentioned that a recipe often provides a procedure (or a \emph{plan}). The
robot should be able to store this plan in a way that allow later execution.
The plan is likely to contain \emph{spatio-temporal constraints} (like ``put
the brownie in the oven for 20 min'' or ``let's cook \emph{for tonight}'') that
must as well be appropriately represented.

To make decision, a robot may also want to \emph{predict} the state of the world
after some action (``if I leave the cake 2h in the oven, it will burn'').
Such ability to project itself in future or, generally speaking, in other
possible state of the world is related to several cognitive ability and
reasoning techniques: \emph{planning}, \emph{representation of possible worlds}
and \emph{non-monotonic reasoning}, in addition to common-sense knowledge and
\emph{physics-based} reasoning (that allows to predict that an egg is likely to
break if dropped).

Procedures are in addition often \emph{underspecified}: we can expect the recipe
to provide a cooking duration, but we usually do not expect the recipe to tell
us to first open the oven door, and then put the cake into it, since it is
self-evident that the door must first be opened to put the cake in the oven.
Such underspecification should be detectable, representable, and ideally
completable by the knowledge representation system\footnote{Note that we do not
assume here the {\it knowledge representation system} to be a single software
component: it may well be the result of the aggregation of several logical
components working together. We come back later on this aspect.}.

% Representation feature that enable cooperation
Then, we want our three agents to cooperate. This, in turn, leads to another
set of cognitive abilities.

Cooperation in our scenario can intervene at many places. For instance, an
agent may want to inform another one about the number of eggs that are
necessary for the brownie. This \emph{helping} behaviour makes sense only if
the first agent knows that the recipient agent both needs the information but
does not know it. This in turn requires the robot to be able to model the
knowledge of the other agents: to think \emph{from the perspective} of another
agent (an idea that is related to the availability of a theory of
mind~\cite{Leslie2000}).

Ability to communicate is one important pre-requisite to collaboration.
Communication in general requires the addresser and the addressee to share a
common interpretative framework (a shared common-sense knowledge -- or cultural
background -- and a shared context)~\cite{Jakobson1960}. In our scenario, the
agents are working in a kitchen. This element of context does not however
suffice if, for example, an agent asks another agent to ``give {[him]} the
bowl''. Behind the symbol ``bowl'', which physical entity are we actually
talking about? If we want to act on the world, this so-called \emph{grounding}
operation is essential, and may be tightly bound to the underlying knowledge
representation system. Note that grounding is a bidirectional process: in
covers the {\it top-down} operation (from the symbol to the percept) and the
{\it bottom-up} converse (retrieval or creation of symbols from perception).

A related ability is called \emph{pre-supposition accommodation}: if one of the
agent moves behind another one, with the brownie dough in its arm, and says
``be careful, I'm behind you!'', we want the first agent to be able to
represent both symbolically and geometrically (because, for instance, if the
agent want to move, it must take into account the new obstacle) something that
was not directly perceived. A knowledge representation system may be able to
provide structures to represent and reason about such cases.

Also central to cooperation are the notions of \emph{joint
intentions} and \emph{joint goals}~\cite{Tomasello2005, Bratman2009}: to help
the human during the cooking session, the robots need to track how far
they are into the recipe, what is the next step the human is likely to go for,
how task are currently split between agents, what action is currently
blocking the procedure, etc. This knowledge should let the robot identify the
intentions of other agents and create accordingly joint goals. Hence, a
knowledge representation system aiming at dealing with cooperative behaviours
is likely to have goal management structures taking explicitly into account
other agents' actions and goals.

In order to effectively share tasks, the robot must also know what it is
capable of: \emph{capability introspection} (both in term of general capability
and of immediate ability) is thus often desirable. More general introspection
(like the ability to tell ``who I am'' or ``what do I think of'') does not
appear to be necessary in our scenario. This may however be required in more
general human-robot interaction.

Last but not least, our scenario assumes implicitly \emph{natural interaction}
between humans and robots (as showed by the casual style of the
order ``Let's make a brownie!''). While natural language processing {\it
per-se} is usually out of the scope of a knowledge representation system, we
may want to be sure these systems may successfully interoperate, \ie that the
knowledge representation system provides efficient support to the natural
language processing module (for instance by adopting models and vocabulary that
are both well suited for machine processing and remain as close as possible to
the humans own structures and vocabulary).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Human-Robot Interaction: the Challenges}
\label{sect|challenges}

\subsection{Specifying the Context}
\label{sect|general-context}

{\em Aperitif time. Sitting down in his comfortable armchair, Tom gives a look
at the empty table. ``{\em Hey robot, put two glasses and this bottle on the
tray!}''. ``{\em And bring that over there.}''. The robot asks ``{\em The
Martini or the Porto?}''. ``{\em Bring both!}'' answers Tom. The robot prepares
the order and smoothly bring the tray to the table.}

\begin{figure}%[!ht] 
    \centering
    \includegraphics[width=0.8\columnwidth]{intro/aperitif_time.jpg} 

    \caption{Interacting with the robot in an everyday situation: the human
    asks for help in vague terms, the robot takes into account the human's {\it
    a priori} knowledge and spatial perspective to refine its understanding of
    the question.} 

    \label{fig|vpt} 
\end{figure}

While the dream of the robot-servant could be questioned, this kind of natural
interaction is a short-term target for the human-robot interaction community.

This simple scenario belongs to the broad class of \emph{interactive
manipulation problems}: several agents agree a (more or less implicit) joint
goal that requires some sort of cooperation to be successfully achieved. These
problems involve both dialogue and manipulation and are often iterative
(step-by-step resolution, questions-answers,...).

\begin{figure}
    \centering
    \includegraphics[width=0.9\columnwidth]{intro/grounding_robot.pdf}
    \caption{A robot reasoning about human-robot interaction and anticipation
    of human activities: sources of in- formation are multi-modal dialogue and
    observation of the environment and the human activities.}
    \label{fig|hri-dec}
\end{figure}


Figure~\ref{fig|hri-dec} illustrates some of the aspects of the interaction.
From the robot perspective, several cognitive skills are involved: dialogue
processing through verbal and deictic modalities (what does the human say? what
attitude -- glances, postures, gestures... -- does he express?), acquisition
and maintainance of one or several models of the environment, not only from the
robot point of view, but also from the other agents' points of view,
anticipation (what are the intentions of the human? Can I predict and
anticipate his/her actions?), planning and control (how would I proceed further
towards the goal?), monitoring of the other agents' activities (do we have an
effective cooperation?) and the overall progress of the task. 

What are the prerequisites for such a sentence --``Robot, put two glasses and
this bottle on the tray''-- to be understood by the robot, correctly
interpreted in the spatial context of the interaction, and eventually
transformed into a set of actions? We summarize these challenges in four
categories:

\begin{enumerate}

    \item how to build and maintain a consistent geometric model of the current
    situation, acquired through perception or deduction from previous
    perceptions,

    \item how to build an unambiguous symbolic representation of concepts
    (objects, agents, actions...) underlying the interaction, and practical for
    decision-making processes,

    \item how to establish the joint goal(s), how to build and maintain
    iteratively shared (human-robot) plans, 

    \item how to refine and execute the computed plans, and how to monitor
    those achieved by its human partner?

\end{enumerate}


This chapter focuses on points {\it 1} and {\it 2}. It presents techniques,
developed and used on several real robots, for the creation of a set of
environment models suitable for grounded situation interpretation,
decision-making and control.

The two other items are however important to actually perform the interaction.
Thus we briefly overview a global architecture of a robot able to cooperate
with humans before really focusing on the grounding issues.




Interaction for \emph{joint action} in a \emph{situated} environment.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Challenges}


Those two broad targets should lead to two improvements for human-robot
interaction:


\begin{itemize}
	\item to loosen the constraints on symbolic modelling of the robot
	environment by providing more expressive representation system than
	classical databases or fact repositories,

	\item to improve human-robot interaction by explicitly providing to the
	machine an interpretation frame, at least partially shared with the human.

\end{itemize}


\fxnote{Put focus on knowledge related challenge => focus on questions that need to be
answered}
\fxnote{Show what is difficult in the scenario, and why this requires research.}

\subsection{Specific requirements of human-robot interaction}
\label{sect|pecularities-krs-for-hri}

Peculiarities on knowledge representation required by HRI, in the frame of the
general context defined in section~\ref{sect|general-context}:

\subsubsection{Human communication}

\begin{figure}%[!ht]
\centering
  \includegraphics[width=0.6\linewidth]{communication/jakobson_communication_model.pdf}
  \caption{The \emph{Communication Model}, as proposed by Jakobson. In bold
  characters are the \emph{communication dimensions}, in italics, the
  corresponding \emph{communication functions}.}
  \label{fig|jakobson_communication_model}
\end{figure}

\subsubsection{Perspective-Taking, False Beliefs, Theory of Mind}

\fxnote{Present here Sally and Ann}

\subsubsection{and also...}

\begin{itemize}
	\item Ability to talk about concepts that are not immediately perceived by
	the robot


	\item \fxerror{TBD: absence of knowledge representation} Ability to
	represent that an agent knows something about something else, even if we do
	not know \emph{what}.

\end{itemize}

\subsection{Targeted applications/experiments}
\label{sect|targeted-applications-experiments}


The operational targets are two-fold:

\begin{inparaenum}[\itshape a\upshape)]

	\item determine, for a abstract/theoritical/general point of view, how and
	why a cognitive architecture could contribute to these aims; and

	\item implement it.

\end{inparaenum}

\begin{itemize}
	\item \textbf{Categorization}: \emph{Odd One Out}-style experiment,
	\item \textbf{Dialogue}: Grounded dialogue,
	\item \textbf{Introspection verbalization}: Integration dialogue/planing, verbalization of plans,
	\fxerror{TDB: integration dialogue/planing + verbalization of plans}
	\item \textbf{Connection to remote knowledge sources}: \emph{DBpedia}, \emph{WordNet}, \emph{KnowRob ontology}...
	\fxerror{TDB: integration remote knowledge sources}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Contributions}
\label{sect|contributions}

This section summarizes the main contributions of the thesis, both from a
scientific point of view and from a technical point of view.

\subsection{Scientific contributions}
\label{sect|scientific-contributions}

The need of a better understanding of the knowledge needs of robotic
applications in human, \ie complex, dynamic, semantically-rich, environments,
is the starting point of my thesis.

Building upon an extensive review of the literature and the formulation of
several interaction scenarii (that themselves led to experiments on real
robots), I have iteratively refined the ``knowledge for interaction'' problem.
The formalization of this question is one of the main scientific outcomes of
this work: I have listed and organized into a typology a set of desirable
characteristics of knowledge representation systems for service robotics.

This typology aims to offer an comprehensive and consistent base to evaluate
existing systems and to draw new research perspectives. It also enables to
better assess the progresses of the Service Robot and Human Robot Interaction
research communities towards the long term goal of \emph{human-level artificial
intelligence} for robots, as would say McCarthy.

Another scientific contribution of this thesis is its participation to
narrow down the gap between research on embodied and disembodied artificial
agents: I have tried to bridge experiences learned from years of research on
disembodied cognitive architectures (both from the computing science and
neuropsychology communities) with the constraints from real-world systems that
weigh on robotic architectures. Notably, I have tried to identify
theoretical reference contributions from the diverse fields of cognitive
sciences that are relevant to \emph{knowledge-enabled} robotics. I have also
proposed reference implementations on robots for some of them.

At the architectural level, my work also helps to better understand the
knowledge flows in modern cognitive architectures for robots. By introducing
\emph{explicit} knowledge in our architectures, it allows the humans that
design and program robots to \emph{talk about} and question this knowledge: it
singularizes and materializes concepts that were beforehand often
diffuse and ubiquitous. This leads us to define the idea and propose an
implementation of a \emph{knowledge-oriented} architecture.

This work has also several more focused scientific contributions. The
centralized semantic architecture that I propose is original. While it
exhibits shortcomings for some cognitive tasks, it also proposes novel efficient
ways to represent and manipulate knowledge simultaneously for multiple agents.
Along with the survey of current knowledge systems that I have conducted,
it effectively completes the panorama of available designs of knowledge
representation systems.

Amongst the cognitive abilities that my developments have enabled, a
particular scientific focus was led on the acquisition and modelling of
multiple, agent-dependent symbolic worlds. This opened new perspectives related
to \emph{perspective-aware} reasoning or \emph{theories of mind} for robots
that are detailed in this work.

I also have a scientific contribution on the grounding of human-robot
dialogue in natural language. We have algorithmically formalized a novel
grounding process that takes advantage of multi-modal communication (verbal,
deictic and immanent) and handles the semantics of several more complex
language features like quantification. This system also has contributions
related to the semantic validation of thematic roles and interactive
disambiguation that takes into account human attentional focus.

\subsection{Technical contributions}
\label{sect|technical-contributions}


This thesis has four major technical contributions: the software development of
\emph{ORO server} as a semantic blackboard dedicated to robotic applications,
the design of the \emph{ORO ontology} as a domain-specific common-sense
ontology tailored for service robotic needs, the pervasive integration of a new
semantic layer into several existing robot architecture, and finally, the
software development of \emph{Dialogs}, a novel module for natural language
grounding.

The main software contribution of the thesis is the development of an
open-source, versatile and light-weight knowledge base that stores in a
formal framework based on first-order logics both the robot's own beliefs and
the mental models of every other cognitive agents that the robot interacts
with. This tool, called \emph{ORO}, is implemented as a
platform/middleware-agnostic server, and exposes to the robot's modules
several advanced reasoning services (via the integration of external
reasoners). This software project is now publicly available, used by other
laboratories, and comes with extensive documentation and bindings for several
mainstream languages (C++, Python...) and middlewares (ROS, YARP).

In parallel of this development, and in collaboration with other developers,
I have also drafted (and partially implemented) a proposal for a standard API
for knowledge manipulation that supports the specific needs of robotic
applications.

Coming along with the ORO server, I introduce in this thesis the
\emph{ORO common-sense ontology} which is a proposal of an upper ontology for
service and interactive robotics. This ontology consists of about two hundred
classes, relations and rules that are significant for the modelling of the
robot's beliefs and state, and the interactions with other agents (humans or
robots). This ontology also tries to stay closely aligned with the standard
{\sc OpenCyc} upper-ontology to guarantee interoperability with semantic
web resources and other robots.

A third technical contribution is the introduction of a new
knowledge-oriented, event driven communication model between high-level
decisional modules: by introducing the concept of \emph{semantic events}, the ORO
server enables the development of new executive layers that combine reactive
behaviour with high-level abstractions: for instance, triggering a behaviour
when a human looks at the robot while sit, can be expressed in our architecture
as a single line of code: {\tt subscribe([* type Human, * looksAt myself, *
isSitting true], behaviour\_callback())}. This highly expressive event model
opens new ranges of development opportunities for decisional modules.

During the preparation of the thesis, I have also developed a new stand-alone
natural language processor for English language. It takes advantage of the
different symbolic models exposed by ORO server to analyse, resolve the
semantics and ground dialogues. It can process orders, questions and positive
assertions and translates them into new symbolic facts. It includes a custom
grammatical parser, a re-verbalization module, several discrimination
strategies, including interactive ones. The application is developed in Python
(about 15K lines of code), can be used in real-time on the robot, and is
accompanied by a speech recognition interface developed as an Android
application.

A last notable software contribution is my involvement in the MORSE simulator
for academic robotics. I have played a central role in the original design and
development of the core functionalities of this open-source simulator which is
now used by over twenty laboratories world-wide. While this project as a whole
is not directly related to the thesis main domain, I have led the effort towards
effective simulation of human-robot interaction in MORSE, which is now the
current state-of-the-art in this domain. It is briefly presented at
section~\ref{sect|simulation}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{A reader's guide}

\subsection*{The thesis in 15min}

Because of the contingencies of this world, we acknowledge that the complete
reading of this thesis may not fit in one's tight schedule.

If you have only about 15 minutes to dedicate to this work, we suggest to read
the following sections in that order:

\begin{itemize} \item What are the challenges? (section~\ref{sect|challenges},
            page~\pageref{sect|challenges}),

    \item Contributions (section~\ref{sect|contributions},
        page~\pageref{sect|contributions}),

    \item The ORO functional overview (section~\ref{sect|functional-overview},
        page~\pageref{sect|functional-overview}),

    \item The first interaction experiment (section~\ref{sect|expe1},
        page~\pageref{sect|expe1}),

    \item The evaluation of ORO and other knowledge representation systems
        (section~\ref{sect|evaluation-oroserver},
        page~\pageref{sect|evaluation-oroserver}),

    \item And finally, the discussion on perspectives
        (section~\ref{sect|perspectives}, page~\pageref{sect|perspectives}),

\end{itemize}

\fxfatal{Re-read these sections to make sure it makes sense}

\subsection*{For the patient reader}

Roughly speaking, the thesis is organized in three parts: an analysis of
knowledge representation systems for service and personal robotic, the
presentation of ORO, our own implementation of such a knowledge representation
system, and finally we report on practical uses of explicit knowledge
manipulation on robots, first for natural language processing, then through
several experiments.

The first part is covered in the chapter~\ref{chapt|krs}: after a discussion on
what we call ``knowledge'' in our context, we explore its importance by
listing, in a typology of characteristics, the requirements of our robots
related to knowledge management. This first chapter is completed by a survey of
eight systems for knowledge management that have been already deployed on real
robots.

At the end of the thesis, we give a second look at these systems to try to
draw a picture of the overall landscape of knowledge representation approaches
in the robotic reseach community, to identify new possible research directions.

The second part is covered by chapters~\ref{chapt|oroserver} and
\ref{chapt|implementation-integration}. Chapter~\ref{chapt|oroserver} presents
the functional side of ORO server, some of the algorithms that are
implemented, and discusses its knowledge model (the ORO \emph{common-sense
ontology}). The technical side is presented in
chapter~\ref{chapt|implementation-integration} where we emphasise the
integration of ORO within a larger robotic architecture. The articulations with
perceptions, planning and control are presented.

Chapters~\ref{chapt|dialogs} and \ref{chapt|evaluation} form the third and last
part of the thesis. Chapter~\ref{chapt|dialogs} details \emph{Dialogs}, a
module for situated dialogue grounding that takes advantage of the symbolic
knowledge exposed by ORO, and chapter~\ref{chapt|evaluation} presents
several evaluations of our work through various experiments conducted during
the four years of the thesis preparation.

We conclude the thesis with a discussion of several issues related to knowledge
management in service robots (importance of embodiement, relationships between
the symbolic and continuous realms, etc.) and some remarks that could further
improve knowledge representation and management in future robotic
architectures.

